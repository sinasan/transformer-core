# Logische Satzerkennung mit Transformer

Dieses Projekt implementiert ein Transformer-basiertes Modell zur Erkennung logisch sinnvoller SÃ¤tze. Das System kann zwischen semantisch korrekten Aussagen und grammatikalisch richtigen, aber logisch unsinnigen SÃ¤tzen unterscheiden.

## ğŸ¯ Ãœberblick

Das Modell klassifiziert SÃ¤tze in zwei Kategorien:
- **Logisch (1)**: Faktisch korrekte Aussagen (z.B. "Die Sonne geht im Osten auf")
- **Nicht logisch (0)**: Semantisch unsinnige Aussagen (z.B. "Der Tisch ist traurig")

### Kernfunktionen

- EigenstÃ¤ndiges Embedding und Transformer-Modell
- Tokenisierung und Vokabulargenerierung
- Pre-Normalization Transformer-Architektur mit Multi-Head Attention
- Umfangreiche Diagnose- und Analysewerkzeuge
- REST-API fÃ¼r Produktivbetrieb

## ğŸ“‹ Projektstruktur

```
â”œâ”€â”€ config.json             # Modellkonfiguration
â”œâ”€â”€ data/                   # DatensÃ¤tze
â”‚   â””â”€â”€ sentences.csv       # Trainingsdaten
â”‚   â””â”€â”€ vocab.json          # Generiertes Vokabular
â”œâ”€â”€ models/                 # Gespeicherte Modelle
â”œâ”€â”€ src/                    # Quellcode
â”‚   â”œâ”€â”€ api.py              # FastAPI-Schnittstelle
â”‚   â”œâ”€â”€ dataset.py          # Daten-Handling und Tokenisierung
â”‚   â”œâ”€â”€ diagnostic_tool.py  # Umfassendes Diagnosewerkzeug
â”‚   â”œâ”€â”€ evaluate.py         # Modellauswertung
â”‚   â”œâ”€â”€ generate_sentences_claude.py # Datengenerierung mit Claude
â”‚   â”œâ”€â”€ generate_sentences_gpt4o.py  # Datengenerierung mit GPT-4o
â”‚   â”œâ”€â”€ model.py            # Transformer-Modell
â”‚   â”œâ”€â”€ rebuild-vocab.py    # Vokabular-Neuerstellung
â”‚   â”œâ”€â”€ test_dataset.py     # Dataset-Tests
â”‚   â”œâ”€â”€ test_model.py       # Modell-Tests
â”‚   â””â”€â”€ train.py            # Trainingslogik
â”œâ”€â”€ docs/                   # ZusÃ¤tzliche Dokumentation
â””â”€â”€ requirements.txt        # AbhÃ¤ngigkeiten
```

## ğŸ› ï¸ Installation

### Voraussetzungen

- Python 3.10+
- PyTorch
- FastAPI (fÃ¼r API-Betrieb)
- Pandas, NumPy, Scikit-learn, Matplotlib

### Einrichtung

1. Repository klonen:
   ```bash
   git clone https://github.com/yourusername/sentence-logic-transformer.git
   cd sentence-logic-transformer
   ```

2. Virtuelle Umgebung erstellen und aktivieren:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Unter Windows: venv\Scripts\activate
   ```

3. AbhÃ¤ngigkeiten installieren:
   ```bash
   pip install -r requirements.txt
   ```

4. Umgebungsvariablen fÃ¼r API-Zugriff (optional fÃ¼r Datengenerierung):
   Erstelle eine `.env`-Datei im Wurzelverzeichnis:
   ```
   OPENAI_API_KEY=dein_openai_key
   ANTHROPIC_API_KEY=dein_anthropic_key
   ```

## ğŸ“Š Datensatz

Der Datensatz besteht aus deutschen SÃ¤tzen, die als "logisch" oder "nicht logisch" gekennzeichnet sind. Es wird eine `sentences.csv` mit folgendem Format verwendet:

```csv
sentence,label
"Die Sonne geht im Osten auf.",1
"Wasser besteht aus Wasserstoff und Sauerstoff.",1
"Der Tisch ist traurig Ã¼ber die Situation.",0
"Berge kÃ¶nnen schwimmen und FlÃ¼sse klettern.",0
```

### Datengenerierung

Das Projekt enthÃ¤lt zwei Skripte zur Datengenerierung:

- **Mit OpenAI GPT-4o**:
  ```bash
  python src/generate_sentences_gpt4o.py --num_per_type 100 --balance-categories
  ```

- **Mit Anthropic Claude**:
  ```bash
  python src/generate_sentences_claude.py --num_per_type 100 --balance-categories
  ```

Weitere Optionen:
- `--force-logical`: Generiert nur logische SÃ¤tze
- `--force-illogical`: Generiert nur unlogische SÃ¤tze
- `--stats`: Zeigt nur Statistiken des vorhandenen Datensatzes

## ğŸ§  Modellarchitektur

Das Modell besteht aus drei Hauptkomponenten:

1. **Embedding-Schicht**:
   - Wandelt WÃ¶rter in numerische Embeddings um
   - Positionsenkodierung fÃ¼r sequentielle Information

2. **Transformer-Encoder**:
   - Multi-Head Attention fÃ¼r kontextuelle Verarbeitung
   - Pre-Normalization fÃ¼r stabiles Training
   - Residual-Verbindungen fÃ¼r besseren Gradientenfluss

3. **Klassifikationsschicht**:
   - Pooling der TokenreprÃ¤sentationen
   - Lineare Projektion fÃ¼r binÃ¤re Klassifikation

### Konfiguration

Die `config.json` steuert die Modellparameter:

```json
{
    "embedding_dim": 256,
    "num_heads": 8,
    "num_layers": 4,
    "num_classes": 2,
    "dropout": 0.2,
    "batch_size": 32,
    "num_epochs": 50,
    "learning_rate": 0.0001
}
```

## ğŸš€ Training

Das Training des Modells erfolgt mit:

```bash
cd src
python train.py
```

Mit Neuaufbau des Vokabulars:

```bash
python train.py --rebuild-vocab
```

Das Modell wird in `models/transformer_model.pth` gespeichert.

## ğŸ“ˆ Evaluation und Diagnose

Das Projekt bietet umfangreiche Diagnosefunktionen:

```bash
python src/diagnostic_tool.py --all --visualize --output-dir results
```

Einzelne Diagnoseoptionen:
- `--evaluate`: Modellbewertung
- `--vocab`: Vokabularanalyse
- `--errors`: Fehleranalyse
- `--test`: BeispielsÃ¤tze testen
- `--sentence "Dein Testsatz"`: Einzelnen Satz testen

FÃ¼r schnelle Auswertung:
```bash
python src/evaluate.py
```

## ğŸŒ API-Nutzung

Starten der API:

```bash
cd src
uvicorn api:app --reload
```

Die API ist unter http://localhost:8000 erreichbar mit folgenden Endpunkten:

- **GET /**: Willkommensseite
- **GET /health**: Healthcheck
- **GET /vocab_info**: Vokabularinformationen
- **GET /test**: Standardbeispiele testen
- **POST /predict**: Satzvorhersage

Beispielanfrage:
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"sentence": "Die Sonne scheint."}'
```

Antwort:
```json
{
  "sentence": "Die Sonne scheint.",
  "prediction": "logisch",
  "confidence": 0.9876,
  "token_count": 4,
  "unknown_words": null,
  "unknown_ratio": 0.0,
  "processing_time": 5.432
}
```

Eine Swagger-UI ist unter http://localhost:8000/docs verfÃ¼gbar.

## ğŸ³ Docker

Das Projekt kann containerisiert werden:

```bash
# Docker-Image bauen
docker build -t sentence-logic-api .

# Container starten
docker run -p 8000:8000 sentence-logic-api
```

## ğŸ”§ Fehlerbehebung

### HÃ¤ufige Probleme

1. **Unbekannte WÃ¶rter**: ÃœberprÃ¼fen Sie mit `diagnostic_tool.py --vocab`, ob wichtige WÃ¶rter im Vokabular fehlen. Bei Bedarf:
   ```bash
   python src/rebuild-vocab.py
   ```

2. **Falsche Vorhersagen**: FÃ¼hren Sie eine Fehleranalyse durch:
   ```bash
   python src/diagnostic_tool.py --errors --visualize
   ```

3. **API-Fehler**: ÃœberprÃ¼fen Sie, ob die richtigen Modell- und Vokabulardateien geladen wurden.

## ğŸ“ Leistung und Ergebnisse

Bei einem ausgewogenen Datensatz mit ~1000 Beispielen kann das Modell eine Genauigkeit von Ã¼ber 95% erreichen. Die Leistung hÃ¤ngt stark von der QualitÃ¤t und GrÃ¶ÃŸe der Trainingsdaten ab.

Empfehlungen fÃ¼r optimale Ergebnisse:
- Mindestens 500 SÃ¤tze je Klasse
- Ausgewogene Verteilung verschiedener Satztypen
- Vokabular mit hÃ¤ufigen WÃ¶rtern und Domainbegriffen

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen! MÃ¶gliche Verbesserungen:
- Erweiterte Tokenisierungsmethoden
- Mehrsprachige UnterstÃ¼tzung
- Feinere Klassifikationskategorien
- Integration in grÃ¶ÃŸere NLP-Pipelines

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz.
